{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"lab.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2 â€“ `pandas` \n",
    "\n",
    "## DSC 80, Fall 2023\n",
    "\n",
    "### Due Date: Monday, October 16th at 11:59PM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "Welcome to the second lab assignment in DSC 80 this quarter!\n",
    "\n",
    "Much like in DSC 10, this Jupyter Notebook contains the statements of the problems and provides code and Markdown cells to display your answers to the problems. Unlike DSC 10, the notebook is *only* for displaying a readable version of your final answers. The coding will be done in an accompanying `lab.py` file that is imported into the current notebook, and **you will only submit that `lab.py` file**, not this notebook!\n",
    "\n",
    "Some additional guidelines:\n",
    "- **Unlike in DSC 10, labs will have both public tests and hidden tests.** The bulk of your grade will come from your scores on hidden tests, which you will only see on Gradescope after the assignment deadline.\n",
    "- **Do not change the function names in the `lab.py` file!** The functions in the `lab.py` file are how your assignment is graded, and they are graded by their name. If you changed something you weren't supposed to, you can find the original code in the [course GitHub repository](https://github.com/dsc-courses/dsc80-2023-sp).\n",
    "- Notebooks are nice for testing and experimenting with different implementations before designing your function in your `lab.py` file. You can write code here, but make sure that all of your real work is in the `lab.py` file, since that's all you're submitting.\n",
    "- **To ensure that all of your work to be submitted is in `lab.py`, we've provided an additional uneditable notebook, called `lab-validation.ipynb`, that contains only the tests and their setup. Make sure you are able to run it top-to-bottom without error before submitting!**\n",
    "- You are encouraged to write your own additional helper functions to solve the lab, as long as they also end up in `lab.py`.\n",
    "\n",
    "**Importing code from `lab.py`**:\n",
    "\n",
    "* Below, we import the `.py` file that's contained in the same directory as this notebook.\n",
    "* We use the `autoreload` notebook extension to make changes to our `lab.py` file immediately available in our notebook. Without this extension, we would need to restart the notebook kernel to see any changes to `lab.py` in the notebook.\n",
    "    - `autoreload` is necessary because, upon import, `lab.py` is compiled to bytecode (in the directory `__pycache__`). Subsequent imports of `lab` merely import the existing compiled python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lab import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: `pandas` Basics ðŸ‘¶\n",
    "\n",
    "In this section, you'll have to implement several functions. The public tests test your functions on an example dataset, which is stored in `data/scores.csv`. You're free to import this `.csv` file as a DataFrame in your notebook and experiment with it. **However,** the functions you write must be general enough such that they can work on other datasets with the same column names but different values.\n",
    "\n",
    "In addition:\n",
    "* Do not hard-code any answers.\n",
    "* Do not use any loops â€“ you will not receive full credit if you do!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "\n",
    "#### `data_load`\n",
    "\n",
    "Complete the implementation of the function `data_load`, which takes in the file path of a dataset to be read as a string and returns the DataFrame that results from following the steps below:\n",
    "    \n",
    "a. First, read in only a subset of the columns: `'name'`, `'tries'`, `'highest_score'`, and `'sex'`.\n",
    "\n",
    "b. Then, drop the `'sex'` column.\n",
    "\n",
    "c. Rename the `'name'` column to `'firstname'` and the `'tries'` column to `'attempts'`.\n",
    "\n",
    "d. Turn the `'firstname'` column into the index.\n",
    "\n",
    "<br>\n",
    "    \n",
    "#### `pass_fail`\n",
    "\n",
    "Complete the implementation of the function `pass_fail`, which takes a DataFrame returned from `data_load` and adds a column `'pass'` that contains `'Yes'` or `'No'` for each row, based on the following conditions:\n",
    "\n",
    "* `'No'` if a number of attempts is strictly larger than 1 but the score is less than 60\n",
    "* `'No'` if a number of attempts is strictly larger than 4 but the score is less than 70\n",
    "* `'No'` if a number of attempts is strictly larger than 6 but the score is less than 90\n",
    "* `'No'` if a number of attempts is strictly larger than 8\n",
    "* `'Yes'` otherwise\n",
    " \n",
    "Your function should return a DataFrame identical to the input `scores` with the column `'pass'` added. However, your function should not modify the original input DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_load(scores_fp):\n",
    "    scores = pd.read_csv(scores_fp,\n",
    "                         usecols=['name', 'tries', 'highest_score', 'sex'],\n",
    "                         )\n",
    "    scores.drop(columns=['sex'], inplace=True)\n",
    "    scores.rename(columns={'name': 'firstname', 'tries': 'attempts'}, inplace=True)\n",
    "    scores.set_index('firstname', inplace=True)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_pass(scores):\n",
    "    if scores['attempts'] > 1 and scores['highest_score'] < 60:\n",
    "        return 'No'\n",
    "    if scores['attempts'] > 4 and scores['highest_score'] < 70:\n",
    "            return 'No'\n",
    "    if scores['attempts'] > 6 and scores['highest_score'] < 90:\n",
    "        return 'No'\n",
    "    if scores['attempts'] > 8:\n",
    "        return 'No'\n",
    "    return 'Yes'\n",
    "\n",
    "\n",
    "def pass_fail(scores):\n",
    "    scores['pass'] = scores.apply(check_pass, axis=1)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't change this cell -- it is needed for the tests to work\n",
    "scores_fp = os.path.join('data', 'scores.csv')\n",
    "scores = data_load(scores_fp)\n",
    "passfail = pass_fail(scores.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attempts</th>\n",
       "      <th>highest_score</th>\n",
       "      <th>pass</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>firstname</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Julia</th>\n",
       "      <td>4</td>\n",
       "      <td>90.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Angelica</th>\n",
       "      <td>2</td>\n",
       "      <td>70.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tyler</th>\n",
       "      <td>2</td>\n",
       "      <td>88.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kathleen</th>\n",
       "      <td>7</td>\n",
       "      <td>88.5</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Axel</th>\n",
       "      <td>5</td>\n",
       "      <td>45.3</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Amiya</th>\n",
       "      <td>2</td>\n",
       "      <td>34.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Marina</th>\n",
       "      <td>2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Torrey</th>\n",
       "      <td>14</td>\n",
       "      <td>99.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mariah</th>\n",
       "      <td>10</td>\n",
       "      <td>98.1</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Grayson</th>\n",
       "      <td>3</td>\n",
       "      <td>67.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yvette</th>\n",
       "      <td>4</td>\n",
       "      <td>55.9</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Marina</th>\n",
       "      <td>3</td>\n",
       "      <td>100.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Marina</th>\n",
       "      <td>2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           attempts  highest_score pass\n",
       "firstname                              \n",
       "Julia             4           90.0  Yes\n",
       "Angelica          2           70.0  Yes\n",
       "Tyler             2           88.0  Yes\n",
       "Kathleen          7           88.5   No\n",
       "Axel              5           45.3   No\n",
       "Amiya             2           34.0   No\n",
       "Marina            2          100.0  Yes\n",
       "Torrey           14           99.0   No\n",
       "Mariah           10           98.1   No\n",
       "Grayson           3           67.0  Yes\n",
       "Yvette            4           55.9   No\n",
       "Marina            3          100.0  Yes\n",
       "Marina            2          100.0  Yes"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pass_fail(scores)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q1</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q1 results: All test cases passed!"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "#### `med_score`\n",
    "\n",
    "Complete the implementation of the function `med_score`, which takes in a DataFrame that is returned by `pass_fail` and returns the median score amongst students who passed the test.\n",
    "\n",
    "<br>\n",
    "\n",
    "#### `highest_score_name`\n",
    "    \n",
    "Complete the implementation of the function `highest_score_name`, which takes in a DataFrame that is returned by `pass_fail` and returns a tuple in which:\n",
    "- The first item is the maximum score any student received.\n",
    "- The second item should be a list of the name(s) of the person(s) with the maximum score (attempts do not count). If just one student received the maximum score, the list you create will have length 1.\n",
    "\n",
    "As a reminder, please follow these requirements:\n",
    "\n",
    "* For all questions you need to write code general enough to be applied to another similar dataset. \n",
    "* Do not hard-code any answers. \n",
    "* Do not use `for` or `while` loops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def med_score(scores):\n",
    "    return scores[scores['pass'] == 'Yes']['highest_score'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Marina', 'Marina', 'Marina'], dtype='object', name='firstname')"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = scores[scores['highest_score'] == 100].index\n",
    "name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def highest_score_name(scores):\n",
    "    highest_score = scores.sort_values('highest_score', ascending=False).iloc[0]['highest_score']\n",
    "    name = scores[scores['highest_score'] == highest_score].index\n",
    "    return (highest_score, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't change this cell -- it is needed for the tests to work\n",
    "medscore = med_score(passfail.copy())\n",
    "highest = highest_score_name(passfail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q2</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q2 results: All test cases passed!"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "Complete the implementation of the function `idx_dup`, which does not take any arguments and returns a single integer, answering the question below:\n",
    "\n",
    "Is it possible for a DataFrame's index to have duplicate values?\n",
    "1. No, index values must be unique and use non-negative integers only, just like in `numpy` arrays.\n",
    "2. No, index values must be unique and use integers only.\n",
    "3. No, index values must be unique but index values are not restricted to integers.\n",
    "4. Yes, but index values must be non-negative integers only.\n",
    "5. Yes, but index values must be integers only.\n",
    "6. Yes, and index values are not restricted to integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idx_dup():\n",
    "    return 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't change this cell -- it is needed for the tests to work\n",
    "idxdup = idx_dup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q3</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q3 results: All test cases passed!"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Tricky Pandas ðŸ¤”\n",
    "\n",
    "Sometimes, `pandas` gives you weird outputs that you may not expect. The next set of questions walks you through a few examples that might surprise you. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "\n",
    "The following subparts all require you to define a function and return a number that is the answer to a multiple-choice question. You may need to write code and experiment with DataFrames to arrive at your answers.\n",
    "\n",
    "#### `trick_me`\n",
    "\n",
    "`trick_me` should not take any arguments. \n",
    "<br>\n",
    "\n",
    "Inside the function:\n",
    "\n",
    "* Create a DataFrame named `tricky_1` that has three columns labeled `'Name'`, `'Name'`, and `'Age'`. `tricky_1` should have 5 rows; the values are up to you.\n",
    "* Save this DataFrame in the `.csv` file called `'tricky_1.csv'` without the index.\n",
    "* Now create another DataFrame, named `tricky_2`, by reading in the file `'tricky_1.csv'`. What are your observations?\n",
    "\n",
    "  1. It was not possible to create a DataFrame with the duplicate columns.\n",
    "  2. `tricky_1` and `tricky_2` have the same column names.\n",
    "  3. `tricky_1` and `tricky_2` have different column names.\n",
    "   \n",
    "Your function should return `1`, `2`, or `3`, answering the above question.\n",
    "\n",
    "<br>\n",
    "  \n",
    "#### `trick_bool`\n",
    "`trick_bool` should not take any arguments.\n",
    "\n",
    "To determine the correct answer from the list below, you should follow the steps outlined by experimenting in **the notebook** (or in the Terminal by running `python`). Outside the function:\n",
    "\n",
    "* Create a DataFrame named `bools` that has four columns: `True`, `True`, `False`, `False`. Each column name should be Boolean.\n",
    "* `bools` should have 4 rows; the values are up to you.\n",
    "* Predict the shape of the DataFrame that results by running each of the three lines of code below. Pick a corresponding answer from the given list. Your function should return a list with three numbers, one for each line.\n",
    "* You should be able to answer without running any code, but feel free to run code to check your answer.\n",
    "* **Your function should not do anything other than return a hardcoded list.**\n",
    "\n",
    "```py\n",
    "df[True]\n",
    "df[[True, True, False, False]]\n",
    "df[[True, False]]\n",
    "```\n",
    "    \n",
    "Answer choices:\n",
    "1. DataFrame: 2 columns, 1 row\n",
    "2. DataFrame: 2 columns, 2 rows\n",
    "3. DataFrame: 2 columns, 3 rows\n",
    "4. DataFrame: 2 columns, 4 rows\n",
    "5. DataFrame: 3 columns, 1 rows\n",
    "6. DataFrame: 3 columns, 2 rows\n",
    "7. DataFrame: 3 columns, 3 rows\n",
    "8. DataFrame: 3 columns, 4 rows\n",
    "9. DataFrame: 4 columns, 1 rows\n",
    "10. DataFrame: 4 columns, 2 rows\n",
    "11. DataFrame: 4 columns, 3 rows\n",
    "12. DataFrame: 4 columns, 4 rows\n",
    "13. Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trick_me():\n",
    "    tricky_1 = pd.DataFrame(\n",
    "                [[\"A\",\"B\", 19],\n",
    "                [\"C\",\"D\", 20],\n",
    "                [\"E\",\"F\", 21],\n",
    "                [\"I\",\"J\", 23],\n",
    "                [\"I\",\"a\", 1]],\n",
    "                columns=['Name', 'Name', 'Age']\n",
    "                )\n",
    "    tricky_1.to_csv('tricky_1.csv', index=False)\n",
    "    tricky_2 = pd.read_csv('tricky_1.csv')\n",
    "    if set(tricky_1.columns) == set(tricky_2.columns):\n",
    "        return 2\n",
    "    else:\n",
    "        return 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trick_me()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>True</th>\n",
       "      <th>True</th>\n",
       "      <th>False</th>\n",
       "      <th>False</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C</td>\n",
       "      <td>D</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E</td>\n",
       "      <td>F</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I</td>\n",
       "      <td>J</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  True True  False  False\n",
       "0    A    B     19      1\n",
       "1    C    D     20      1\n",
       "2    E    F     21      1\n",
       "3    I    J     23      1"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bools = pd.DataFrame(\n",
    "[[\"A\",\"B\", 19, 1],\n",
    " [\"C\",\"D\", 20, 1],\n",
    " [\"E\",\"F\", 21, 1],\n",
    " [\"I\",\"J\", 23, 1]],\n",
    "columns=[True, True, False, False]\n",
    ")\n",
    "bools\n",
    "# bools[True]\n",
    "# bools[[True, True, False, False]]\n",
    "# bools[[True, False]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't change this cell -- it is needed for the tests to work\n",
    "trick_ans = trick_bool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q4</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q4 results: All test cases passed!"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5\n",
    "\n",
    "In the notebook, use the line of code given below to create a DataFrame named `nans`. Note that we use `np.NaN` (`numpy`'s representation of \"Not a Number\") to create missing values.\n",
    " \n",
    "```py\n",
    "nans = pd.DataFrame([[0, 1, np.NaN], [np.NaN, np.NaN, np.NaN], [1, 2, 3]])\n",
    "```\n",
    "Now, you decide to make your DataFrame more interpretable for data scientists who don't yet know about `np.NaN`, and replace each `np.NaN` with the string `'MISSING'`. In order to do that, you've written the following function:\n",
    "\n",
    "```py\n",
    "def change(x):\n",
    "    if x == np.NaN:\n",
    "        return 'MISSING'\n",
    "    else:\n",
    "        return x\n",
    "```\n",
    "\n",
    "In your notebook, write a line of code that applies the function above to the last column of the `nans` DataFrame. What was a result?\n",
    "* A: It worked: all `np.NaN`s in the last column were changed to `\"MISSING\"`.\n",
    "* B: It did not work.\n",
    "\n",
    "You should end up answering B. What happened? ðŸ¤” It turns out that you can't use simple comparison `==` to detect if a value is `np.NaN`. You need to use another way to compare a value to `np.NaN`. [Read more about it here](https://stackoverflow.com/questions/41342609/the-difference-between-comparison-to-np-nan-and-isnull).\n",
    "\n",
    "<br>\n",
    "\n",
    "#### `change`\n",
    "\n",
    "Once you've read the aforementioned article, fix `change` so that it works as intended.\n",
    "\n",
    "<br>\n",
    "\n",
    "####  `correct_replacement`\n",
    "Complete the implementation of the function `correct_replacement`, which takes in a DataFrame like `nans` and uses your updated `change` function to replace all of the `np.NaN`s in the input DataFrame (in all columns) with `'MISSING'`.\n",
    "\n",
    "* You **cannot** use the `fillna` method, though the `applymap` method might be useful.\n",
    "* Make sure **not** to modify the input DataFrame in-place. Instead, return a new DataFrame.\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "####  `missing_ser`\n",
    "\n",
    "Complete the implementation of the function `missing_ser`, which does not take any arguments and returns the answer to the following multiple choice question.\n",
    "\n",
    "Consider a Series named `ser` that has six elements:\n",
    "\n",
    "```py\n",
    "ser = pd.Series([np.NaN, 'DSC 80', np.NaN, 'King Triton', 'Queen Triton', np.NaN])\n",
    "```\n",
    "\n",
    "What would be the result of running the following code?\n",
    "\n",
    "```py\n",
    "ser[ser.isna()] = 'MISSING'\n",
    "```\n",
    "\n",
    "* Predict the output of running the lines of code above. Pick a corresponding answer from the given options below, and have `missing_ser` return that number.\n",
    "* You should be able to answer without running any code, but feel free to run code to check your answer.\n",
    "* **Your function should not do anything other than return a hardcoded answer.**\n",
    "\n",
    "\n",
    "1. `pd.Series([np.NaN, 'MISSING', np.NaN, 'MISSING', 'MISSING', np.NaN])`\n",
    "2. `pd.Series(['MISSING', 'DSC80', 'MISSING', 'King Triton', 'Queen Triton', 'MISSING'])`\n",
    "3. Error. The code would not run.\n",
    "      \n",
    "<br>\n",
    "        \n",
    "####  `fill_ser`\n",
    "\n",
    "Complete the implementation of the function `fill_ser`, which takes in a DataFrame with many `np.NaN`s and replaces each `np.NaN` with the string `'MISSING'` instead. This modification should be **in-place**, meaning that the function **should not return anything** and should simply modify the DataFrame given as input.\n",
    "\n",
    "As a reminder, please follow these requirements:\n",
    "\n",
    "* You need to write code general enough to be applied to a different DataFrame. \n",
    "* Do not hard-code any answers. \n",
    "* `loop` over the columns *is* allowed but `applymap` *is not* allowed.\n",
    "* `apply` and `fillna` are not allowed.\n",
    "* You shouldn't use use any method for this function (`loc` *is not* a method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2\n",
       "0  0.0  1.0  NaN\n",
       "1  NaN  NaN  NaN\n",
       "2  1.0  2.0  3.0"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nans = pd.DataFrame([[0, 1, np.NaN], [np.NaN, np.NaN, np.NaN], [1, 2, 3]])\n",
    "nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def change(x):\n",
    "    if np.isnan(x):\n",
    "        return 'MISSING'\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    MISSING\n",
       "1    MISSING\n",
       "2        3.0\n",
       "Name: 2, dtype: object"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nans[2].apply(change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def correct_replacement(df_with_nans):\n",
    "    df_with_nans_copy = df_with_nans.copy()\n",
    "    return df_with_nans_copy.applymap(change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MISSING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MISSING</td>\n",
       "      <td>MISSING</td>\n",
       "      <td>MISSING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0        1        2\n",
       "0      0.0      1.0  MISSING\n",
       "1  MISSING  MISSING  MISSING\n",
       "2      1.0      2.0      3.0"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_replacement(nans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0             NaN\n",
       "1          DSC 80\n",
       "2             NaN\n",
       "3     King Triton\n",
       "4    Queen Triton\n",
       "5             NaN\n",
       "dtype: object"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser = pd.Series([np.NaN, 'DSC 80', np.NaN, 'King Triton', 'Queen Triton', np.NaN])\n",
    "ser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         MISSING\n",
       "1          DSC 80\n",
       "2         MISSING\n",
       "3     King Triton\n",
       "4    Queen Triton\n",
       "5         MISSING\n",
       "dtype: object"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser[ser.isna()] = 'MISSING'\n",
    "ser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_ser():\n",
    "    return 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_ser(df_with_nans):\n",
    "    for i in df_with_nans.columns:\n",
    "        df_with_nans.loc[df_with_nans[i].isna(), i] = 'MISSING'\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q5</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q5 results: All test cases passed!"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Summary Statistics ðŸ“Š\n",
    "\n",
    "In this question you will define two general purpose functions that make it easy to qualitatively assess the contents of a DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "\n",
    "Complete the implementation of the function `population_stats`, which takes in a DataFrame `df` and returns a DataFrame indexed by the columns of `df`, with the following columns:\n",
    "* `'num_nonnull'`, which contains the number of non-null entries in each column.\n",
    "* `'prop_nonnull'`, which contains the proportion of entries in each column that are non-null.\n",
    "* `'num_distinct'`, which contains the number of distinct non-null entries in each column.\n",
    "* `'prop_distinct'`, which contains the proportion of non-null entries that are distinct in each column.\n",
    "       \n",
    "For example, if `df` has a column named `'ages'` with the following elements:\n",
    "       \n",
    "```py\n",
    "[2, 2, 2, np.NaN, 5, 7, 5, 10, 11, np.NaN]\n",
    "```\n",
    "\n",
    "Then:\n",
    "- `'num_nonnull'` is 8, and `'prop_nonnull'` is $\\frac{8}{10}$ = 0.8.\n",
    "- There are six distinct entries, `[2, 5, 7, 10, 11, np.NaN]`, but only 5 of them are non-null. So the number of distinct non-null entries, `'num_distinct'`, is 5.\n",
    "- There are 5 distinct non-null entries, and there are 8 total non-null entries, so `'prop_distinct'` is $\\frac{5}{8}$ = 0.625.\n",
    "\n",
    "Putting it all together, `population_stats(df).loc['ages']` should be a Series containing the numbers 8, 0.8, 5, and 0.625."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "def population_stats(df):\n",
    "    num_nonnull = df.count()\n",
    "    prop_nonnull = num_nonnull / len(df)\n",
    "    num_distinct = df.nunique()\n",
    "    prop_distinct = num_distinct / num_nonnull\n",
    "    stats_df = pd.DataFrame({\n",
    "        'num_nonnull': num_nonnull,\n",
    "        'prop_nonnull': prop_nonnull,\n",
    "        'num_distinct': num_distinct,\n",
    "        'prop_distinct': prop_distinct\n",
    "    })\n",
    "    return stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't change this cell -- it is needed for the tests to work\n",
    "pop_data = np.random.choice(range(10), size=(100, 4))\n",
    "df_pop = pd.DataFrame(pop_data, columns='A B C D'.split())\n",
    "out_pop = population_stats(df_pop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q6</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q6 results: All test cases passed!"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q6\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7\n",
    "    \n",
    "Complete the implementation of the function `most_common`, which takes in a DataFrame `df` and a number `N` and returns a DataFrame of the `N` most-common values and their counts for each column of `df`. Any column with fewer than `N` distinct values should contain `np.NaN` in those entries.\n",
    "\n",
    "For example, consider the DataFrame shown on the left. This DataFrame is a subset of `salaries`, a larger DataFrame containing information on employees in the City of San Diego. The subset below contains two of the original columns: `'Job Title'` which contains job titles for employees, and `'status'` which denotes whether the employee works a full time position (`'FT'`) or a part time position (`'PT'`). On the right, the return value of `most_common(salaries, N=5)` is shown.\n",
    "\n",
    "You can assume that there is no ties in our hidden tests.\n",
    "\n",
    "<table><tr>\n",
    "    <td><img src=\"data/imgs/dataframe.png\" width=\"90%\"/></td>\n",
    "    <td><img src=\"data/imgs/most_common.png\" width=\"90%\"/></td>\n",
    "</tr></table>\n",
    "\n",
    "***Note:*** You can loop through the *columns* of `df` to construct your output. You should **not** be looping through rows.\n",
    "\n",
    "***Hint:*** You may find that initializing an empty DataFrame with `N` rows and adding columns to it is useful in your implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_common(df, N=10):\n",
    "    result_df = pd.DataFrame(index=range(N))\n",
    "    for i in df.columns:\n",
    "        common = df[i].value_counts().head(N)\n",
    "        if len(common.index) == N:\n",
    "            result_df[i + '_values'] = common.index\n",
    "            result_df[i + '_counts'] = common.values\n",
    "        else:\n",
    "            result_df[i + '_values'].loc[:len(common.index)] = common.index\n",
    "            result_df[i + '_counts'].loc[:len(common.index)] = common.values\n",
    "            result_df[i + '_values'].iloc[len(common.index):] = np.NaN\n",
    "            result_df[i + '_counts'].iloc[len(common.index):] = np.NaN\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A_values</th>\n",
       "      <th>A_counts</th>\n",
       "      <th>B_values</th>\n",
       "      <th>B_counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A_values  A_counts  B_values  B_counts\n",
       "0         9        15         7        14\n",
       "1         0        15         6        12\n",
       "2         6        15         3        12"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# don't change this cell -- it is needed for the tests to work\n",
    "common_data = np.random.choice(range(10), size=(100, 2))\n",
    "common_df = pd.DataFrame(common_data, columns='A B'.split())\n",
    "common_out = most_common(common_df, N=3)\n",
    "common_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q7</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q7 results: All test cases passed!"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q7\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Superheroes ðŸ¦¸\n",
    "\n",
    "The questions below analyze a dataset of superheroes found in the `data` directory. One of the datasets lists the attributes of each superhero, while the other is a *Boolean* DataFrame describing which superheroes have which superpowers. Note, the datasets contain information on both **good** superheroes, as well as **bad** superheroes (AKA villains).\n",
    "\n",
    "If you took DSC 10 in Fall 2021, this dataset may seem familiar â€“ it was used for the Final Project that quarter!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8\n",
    "\n",
    "Let's start working with the `powers` dataset, which you can see in `data/superheroes_powers.csv`. \n",
    "\n",
    "Complete the implementation of the function `super_hero_powers`, which takes in a DataFrame like `powers` and returns a list with the following three entries:\n",
    "\n",
    "1. The name of the superhero with the greatest number of superpowers.\n",
    "2. The name of the second most common superpower among superheroes who can fly (the most common being `'Flight'` itself).\n",
    "3. The name of the most common superpower among superheroes with only one superpower.\n",
    "\n",
    "You should **not** be hard-coding your answers in this question; your function should work on any DataFrame similar to `powers`. You should not be using loops in this question. In each case, you can assume the answer is unique.\n",
    "\n",
    "***Hint:*** You may find the `idxmax` method useful in this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xw/k8_5xk3s5rs1q7zmzl4k9hkc0000gn/T/ipykernel_3652/2161595783.py:5: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  num_power = powers.sum(axis=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Spectre'"
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "super_fp = os.path.join('data', 'superheroes_powers.csv')\n",
    "powers = pd.read_csv(super_fp)\n",
    "# new_num = powers[powers['Flight'] == True].sum(axis=1)\n",
    "# powers.assign(new_num = new_num).sort_values('new_num', ascending=False)['hero_names'].iloc[0]\n",
    "num_power = powers.sum(axis=1)\n",
    "powers.assign(new_num = num_power).set_index('hero_names')['new_num'].idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Super Strength'"
      ]
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fly = powers[powers['Flight'] == True]\n",
    "result = fly.drop(columns=['Flight']).set_index('hero_names')\n",
    "result.sum().idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xw/k8_5xk3s5rs1q7zmzl4k9hkc0000gn/T/ipykernel_3652/1191178783.py:1: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  num_power = powers.sum(axis=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Intelligence'"
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_power = powers.sum(axis=1)\n",
    "powers.assign(num_power = num_power)\n",
    "powers_copy = powers.assign(num_power = num_power)[powers.assign(num_power = num_power)['num_power'] == 1]\n",
    "powers_copy.set_index('hero_names').drop(columns=['num_power']).sum().idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "def super_hero_powers(powers):\n",
    "    num_power = powers.sum(axis=1)\n",
    "    name = powers.assign(new_num = num_power).set_index('hero_names')['new_num'].idxmax()\n",
    "    \n",
    "    fly = powers[powers['Flight'] == True]\n",
    "    result = fly.drop(columns=['Flight']).set_index('hero_names')\n",
    "    second_common = result.sum().idxmax()\n",
    "    \n",
    "    num_power = powers.sum(axis=1)\n",
    "    powers.assign(num_power = num_power)\n",
    "    powers_copy = powers.assign(num_power = num_power)[powers.assign(num_power = num_power)['num_power'] == 1]\n",
    "    common_power = powers_copy.set_index('hero_names').drop(columns=['num_power']).sum().idxmax()\n",
    "    return [name, second_common,common_power]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xw/k8_5xk3s5rs1q7zmzl4k9hkc0000gn/T/ipykernel_3652/2532135955.py:2: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  num_power = powers.sum(axis=1)\n",
      "/var/folders/xw/k8_5xk3s5rs1q7zmzl4k9hkc0000gn/T/ipykernel_3652/2532135955.py:9: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  num_power = powers.sum(axis=1)\n"
     ]
    }
   ],
   "source": [
    "# don't change this cell -- it is needed for the tests to work\n",
    "super_fp = os.path.join('data', 'superheroes_powers.csv')\n",
    "powers = pd.read_csv(super_fp)\n",
    "super_out = super_hero_powers(powers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q8</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q8 results: All test cases passed!"
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 9\n",
    "\n",
    "In the notebook, load in the dataset in `data/superheroes.csv` as a DataFrame and explore it. Call your `population_stats` function from Question 6 on the DataFrame. You should notice that there are very few actually null (`np.NaN`) values, but there are many entries that **should** be null.\n",
    "\n",
    "Complete the implementation of the function `clean_heroes`, which takes in a DataFrame like the one mentioned above and returns a new DataFrame with all of the missing values replaced with `np.NaN`.\n",
    "\n",
    "***Note:*** Most of the work in this question is identifying how the missing values are stored in the DataFrame. The implementation of the function should only take one line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_stats(powers)\n",
    "def clean_heroes(heroes):\n",
    "    return heroes.replace('-', np.NaN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't change this cell -- it is needed for the tests to work\n",
    "superheroes_fp = os.path.join('data', 'superheroes.csv')\n",
    "heroes = pd.read_csv(superheroes_fp, index_col=0)\n",
    "clean_out = clean_heroes(heroes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q9</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q9 results: All test cases passed!"
      ]
     },
     "execution_count": 438,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q9\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we have displayed the first 10 rows of the cleaned DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Eye color</th>\n",
       "      <th>Race</th>\n",
       "      <th>Hair color</th>\n",
       "      <th>Height</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Skin color</th>\n",
       "      <th>Alignment</th>\n",
       "      <th>Weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A-Bomb</td>\n",
       "      <td>Male</td>\n",
       "      <td>yellow</td>\n",
       "      <td>Human</td>\n",
       "      <td>No Hair</td>\n",
       "      <td>203.0</td>\n",
       "      <td>Marvel Comics</td>\n",
       "      <td>NaN</td>\n",
       "      <td>good</td>\n",
       "      <td>441.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abe Sapien</td>\n",
       "      <td>Male</td>\n",
       "      <td>blue</td>\n",
       "      <td>Icthyo Sapien</td>\n",
       "      <td>No Hair</td>\n",
       "      <td>191.0</td>\n",
       "      <td>Dark Horse Comics</td>\n",
       "      <td>blue</td>\n",
       "      <td>good</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abin Sur</td>\n",
       "      <td>Male</td>\n",
       "      <td>blue</td>\n",
       "      <td>Ungaran</td>\n",
       "      <td>No Hair</td>\n",
       "      <td>185.0</td>\n",
       "      <td>DC Comics</td>\n",
       "      <td>red</td>\n",
       "      <td>good</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Abomination</td>\n",
       "      <td>Male</td>\n",
       "      <td>green</td>\n",
       "      <td>Human / Radiation</td>\n",
       "      <td>No Hair</td>\n",
       "      <td>203.0</td>\n",
       "      <td>Marvel Comics</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bad</td>\n",
       "      <td>441.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Abraxas</td>\n",
       "      <td>Male</td>\n",
       "      <td>blue</td>\n",
       "      <td>Cosmic Entity</td>\n",
       "      <td>Black</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>Marvel Comics</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bad</td>\n",
       "      <td>-99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Absorbing Man</td>\n",
       "      <td>Male</td>\n",
       "      <td>blue</td>\n",
       "      <td>Human</td>\n",
       "      <td>No Hair</td>\n",
       "      <td>193.0</td>\n",
       "      <td>Marvel Comics</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bad</td>\n",
       "      <td>122.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Adam Monroe</td>\n",
       "      <td>Male</td>\n",
       "      <td>blue</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Blond</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>NBC - Heroes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>good</td>\n",
       "      <td>-99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Adam Strange</td>\n",
       "      <td>Male</td>\n",
       "      <td>blue</td>\n",
       "      <td>Human</td>\n",
       "      <td>Blond</td>\n",
       "      <td>185.0</td>\n",
       "      <td>DC Comics</td>\n",
       "      <td>NaN</td>\n",
       "      <td>good</td>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Agent 13</td>\n",
       "      <td>Female</td>\n",
       "      <td>blue</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Blond</td>\n",
       "      <td>173.0</td>\n",
       "      <td>Marvel Comics</td>\n",
       "      <td>NaN</td>\n",
       "      <td>good</td>\n",
       "      <td>61.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Agent Bob</td>\n",
       "      <td>Male</td>\n",
       "      <td>brown</td>\n",
       "      <td>Human</td>\n",
       "      <td>Brown</td>\n",
       "      <td>178.0</td>\n",
       "      <td>Marvel Comics</td>\n",
       "      <td>NaN</td>\n",
       "      <td>good</td>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            name  Gender Eye color               Race Hair color  Height  \\\n",
       "0         A-Bomb    Male    yellow              Human    No Hair   203.0   \n",
       "1     Abe Sapien    Male      blue      Icthyo Sapien    No Hair   191.0   \n",
       "2       Abin Sur    Male      blue            Ungaran    No Hair   185.0   \n",
       "3    Abomination    Male     green  Human / Radiation    No Hair   203.0   \n",
       "4        Abraxas    Male      blue      Cosmic Entity      Black   -99.0   \n",
       "5  Absorbing Man    Male      blue              Human    No Hair   193.0   \n",
       "6    Adam Monroe    Male      blue                NaN      Blond   -99.0   \n",
       "7   Adam Strange    Male      blue              Human      Blond   185.0   \n",
       "8       Agent 13  Female      blue                NaN      Blond   173.0   \n",
       "9      Agent Bob    Male     brown              Human      Brown   178.0   \n",
       "\n",
       "           Publisher Skin color Alignment  Weight  \n",
       "0      Marvel Comics        NaN      good   441.0  \n",
       "1  Dark Horse Comics       blue      good    65.0  \n",
       "2          DC Comics        red      good    90.0  \n",
       "3      Marvel Comics        NaN       bad   441.0  \n",
       "4      Marvel Comics        NaN       bad   -99.0  \n",
       "5      Marvel Comics        NaN       bad   122.0  \n",
       "6       NBC - Heroes        NaN      good   -99.0  \n",
       "7          DC Comics        NaN      good    88.0  \n",
       "8      Marvel Comics        NaN      good    61.0  \n",
       "9      Marvel Comics        NaN      good    81.0  "
      ]
     },
     "execution_count": 492,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_out.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 10\n",
    "\n",
    "Using the **cleaned** superhero data, we will now generate some insights.\n",
    "\n",
    "Complete the implementation of the function `super_hero_stats`, which takes no arguments and returns a list of length 6 containing your answers to the questions below. **Your answers should be hard-coded in the function.**\n",
    "\n",
    "0. What is the name of the tallest `'Mutant'` with `'No Hair'`?\n",
    "1. Among the publishers who have more than 5 characters, which publisher has the highest proportion of human characters? If there is a tie, return the publisher whose name is first alphabetically. We define a character to be human if their `'Race'` is exactly the string `'Human'`; for instance, a `'Race'` of `'Human / Radiation'` is non-human for the purposes of this question.\n",
    "2. Among the characters whose `'Height'`s we know, who is taller on average â€“ `'good'` characters or `'bad'` characters?\n",
    "3. Which publisher has a greater proportion of `'bad'` characters â€“ `'Marvel Comics'` or `'DC Comics'`?\n",
    "4. Which `'Publisher'` that isn't `'Marvel Comics'` or `'DC Comics'` has the most characters? Consider all characters whose `'Publisher'` we know â€“ that is, don't drop rows because they have null values in other columns.\n",
    "5. There is only one character that is **both** more one standard deviation above the mean in height and more than one standard deviation below the mean in weight. What is their name?\n",
    "\n",
    "***Note:*** Although you'll be writing code to find the answers, you should not include your code in your `.py` file. Just return a hard-coded list with your answers to the 6 questions; all 6 elements in the list should be strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Onslaught'"
      ]
     },
     "execution_count": 493,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_out[(clean_out['Hair color']== 'No Hair') & (clean_out['Race']== 'Mutant')].set_index('name')['Height'].idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'George Lucas'"
      ]
     },
     "execution_count": 494,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "publishers_with_more_than_5 = clean_out.groupby('Publisher').filter(lambda x: len(x) > 5)\n",
    "proportion_humans = publishers_with_more_than_5[publishers_with_more_than_5['Race'] == 'Human'].groupby('Publisher').size() / publishers_with_more_than_5.groupby('Publisher').size()\n",
    "publisher_with_highest_human_prop = proportion_humans.idxmax()\n",
    "publisher_with_highest_human_prop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98.87762096774195\n",
      "105.54202898550724\n"
     ]
    }
   ],
   "source": [
    "good_h = clean_out[clean_out['Alignment'] == 'good']['Height'].sum()/clean_out[clean_out['Alignment'] == 'good']['Height'].count()\n",
    "bad_h = clean_out[clean_out['Alignment'] == 'bad']['Height'].sum()/clean_out[clean_out['Alignment'] == 'bad']['Height'].count()\n",
    "print(good_h)\n",
    "print(bad_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "good       259\n",
       "bad        115\n",
       "neutral     11\n",
       "Name: Alignment, dtype: int64"
      ]
     },
     "execution_count": 507,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_out[clean_out['Publisher'] == 'Marvel Comics']['Alignment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "good       142\n",
       "bad         59\n",
       "neutral     13\n",
       "Name: Alignment, dtype: int64"
      ]
     },
     "execution_count": 508,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_out[clean_out['Publisher'] == 'DC Comics']['Alignment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't change this cell -- it is needed for the tests to work\n",
    "stats_out = super_hero_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NBC - Heroes'"
      ]
     },
     "execution_count": 520,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_out[(clean_out['Publisher'] != 'DC Comics') & (clean_out['Publisher'] != 'Marvel Comics')].groupby('Publisher').count()['name'].idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Eye color</th>\n",
       "      <th>Race</th>\n",
       "      <th>Hair color</th>\n",
       "      <th>Height</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Skin color</th>\n",
       "      <th>Alignment</th>\n",
       "      <th>Weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>Groot</td>\n",
       "      <td>Male</td>\n",
       "      <td>yellow</td>\n",
       "      <td>Flora Colossus</td>\n",
       "      <td>NaN</td>\n",
       "      <td>701.0</td>\n",
       "      <td>Marvel Comics</td>\n",
       "      <td>NaN</td>\n",
       "      <td>good</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      name Gender Eye color            Race Hair color  Height      Publisher  \\\n",
       "302  Groot   Male    yellow  Flora Colossus        NaN   701.0  Marvel Comics   \n",
       "\n",
       "    Skin color Alignment  Weight  \n",
       "302        NaN      good     4.0  "
      ]
     },
     "execution_count": 537,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_out['Weight'].replace(-99, np.NaN, inplace=True)\n",
    "clean_out['Height'].replace(-99, np.NaN, inplace=True)\n",
    "mean_height = clean_out['Height'].mean()\n",
    "std_height = clean_out['Height'].std()\n",
    "mean_weight = clean_out['Weight'].mean()\n",
    "std_weight = clean_out['Weight'].std()\n",
    "character_above_std = clean_out[(clean_out['Height'] > (mean_height + std_height)) & (clean_out['Weight'] < (mean_weight - std_weight))]#['name'].values[0]\n",
    "character_above_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Congratulations! You're done with Lab 2! ðŸ\n",
    "\n",
    "As a reminder, all of the work you want to submit needs to be in `lab.py`.\n",
    "\n",
    "To verify that all of your work is indeed in `lab.py`, and that you didn't accidentally implement a function in this notebook and not in `lab.py`, we've included another notebook in the lab folder, called `lab-validation.ipynb`. `lab-validation.ipynb` is a version of this notebook with only the `grader.check` cells and the code needed to set up the tests. \n",
    "\n",
    "### **Go to `lab-validation.ipynb`, and go to Kernel > Restart & Run All.** This will check if all `grader.check` test cases pass using just the code in `lab.py`.\n",
    "\n",
    "Once you're able to pass all test cases in `lab-validation.ipynb`, including the call to `grader.check_all()` at the very bottom, then you're ready to submit your `lab.py` (and only your `lab.py`) to Gradescope. Once submitting to Gradescope, make sure to stick around until all test cases pass.\n",
    "\n",
    "There is also a call to `grader.check_all()` below in _this_ notebook, but make sure to also follow the steps above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "To double-check your work, the cell below will rerun all of the autograder tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check_all()"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "nteract": {
   "version": "0.15.0"
  },
  "otter": {
   "tests": {
    "q1": {
     "name": "q1",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> isinstance(scores, pd.DataFrame)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> list(scores.columns) == ['attempts', 'highest_score']\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> not isinstance(scores.index[0], int)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> isinstance(passfail, pd.DataFrame)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> len(passfail.columns) == 3\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> passfail.loc[\"Julia\", \"pass\"] == 'Yes'\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q10": {
     "name": "q10",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> isinstance(stats_out[0], str)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> isinstance(stats_out[1], str)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> stats_out[2] in ['good', 'bad']\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> stats_out[3] in ['Marvel Comics', 'DC Comics']\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> isinstance(stats_out[4], str)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> isinstance(stats_out[5], str)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2": {
     "name": "q2",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> isinstance(medscore, float)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> 89 < medscore < 91\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> isinstance(highest, tuple)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> len(highest[1]) == 3\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3": {
     "name": "q3",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> isinstance(idxdup, int)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> 1 <= idxdup <= 6\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4": {
     "name": "q4",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> ans =  trick_me()\n>>> ans == 1 or ans == 2 or ans == 3\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> isinstance(trick_ans, list)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> isinstance(trick_ans[1], int)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q5": {
     "name": "q5",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> change(1.0) == 1.0\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> change(np.NaN) == 'MISSING'\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> df_with_nans = pd.DataFrame([[0, 1, np.NaN], [np.NaN, np.NaN, np.NaN], [1, 2, 3]])\n>>> A = correct_replacement(df_with_nans)\n>>> ((A.values == 'MISSING').sum() == 4) & (A is not df_with_nans)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> ans =  missing_ser()\n>>> ans == 1 or ans == 2 or ans == 3\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> df_with_nans = pd.DataFrame([[0, 1, np.NaN], [np.NaN, np.NaN, np.NaN], [1, 2, 3]])\n>>> fill_ser(df_with_nans)\n>>> (df_with_nans.values == 'MISSING').sum() == 4\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q6": {
     "name": "q6",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> out_pop.index.tolist() == ['A', 'B', 'C', 'D']\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> cols = ['num_nonnull', 'prop_nonnull', 'num_distinct', 'prop_distinct']\n>>> out_pop.columns.tolist() == cols\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> (out_pop['num_distinct'] <= 10).all()\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> (out_pop['prop_nonnull'] == 1.0).all()\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q7": {
     "name": "q7",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> common_out.index.tolist() == [0, 1, 2]\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> common_out.columns.tolist() == ['A_values', 'A_counts', 'B_values', 'B_counts']\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> common_out['A_values'].isin(range(10)).all()\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q8": {
     "name": "q8",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> isinstance(super_out, list)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> len(super_out) == 3\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> all([isinstance(x, str) for x in super_out])\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q9": {
     "name": "q9",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> clean_out['Skin color'].isnull().any()\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> clean_out['Weight'].isnull().any()\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
